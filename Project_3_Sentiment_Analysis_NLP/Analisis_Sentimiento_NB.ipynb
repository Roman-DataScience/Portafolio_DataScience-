{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a716280e-c9ec-4f4a-80ec-3c21a0bc40ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# --- 1. Carga de Datos ---\n",
    "# Asegura que la variable df_text est√© definida\n",
    "# Si esta l√≠nea da error, la variable no est√° en memoria.\n",
    "df_text = pd.read_csv('TestReviews.csv', encoding='ISO-8859-1')\n",
    "df_text.rename(columns={'class': 'sentiment'}, inplace=True)\n",
    "\n",
    "# --- 2. Configuraci√≥n y Descarga de NLTK ---\n",
    "print(\"Configurando NLTK...\")\n",
    "try:\n",
    "    # Descargar los recursos esenciales y el nuevo faltante (punkt_tab)\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    # ¬°Agregamos el recurso que el error te pidi√≥!\n",
    "    nltk.download('punkt_tab', quiet=True) \n",
    "except Exception as e:\n",
    "    print(f\"Advertencia: Hubo un error en la descarga de NLTK: {e}\")\n",
    "\n",
    "# Definir la lista de Stop Words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(\"Stop words y recursos cargados.\")\n",
    "\n",
    "# --- 3. Funci√≥n de Limpieza de Texto ---\n",
    "def limpiar_texto(texto):\n",
    "    # a. Normalizaci√≥n: convertir a min√∫sculas\n",
    "    texto = texto.lower()\n",
    "\n",
    "    # b. Eliminaci√≥n de Ruido: quitar puntuaci√≥n y n√∫meros (solo dejar a-z y espacios)\n",
    "    texto = re.sub(r'[^a-z\\s]', '', texto)\n",
    "\n",
    "    # c. Tokenizaci√≥n (dividir en palabras)\n",
    "    tokens = word_tokenize(texto)\n",
    "\n",
    "    # d. Eliminaci√≥n de Stop Words y palabras cortas (longitud <= 2)\n",
    "    tokens_limpios = [\n",
    "        word for word in tokens if word not in stop_words and len(word) > 2\n",
    "    ]\n",
    "\n",
    "    # Reconstruir el texto limpio\n",
    "    return \" \".join(tokens_limpios)\n",
    "\n",
    "# --- 4. Aplicaci√≥n y Verificaci√≥n ---\n",
    "df_text['review_clean'] = df_text['review'].apply(limpiar_texto)\n",
    "\n",
    "# Inspeccionar el resultado comparando la rese√±a original con la limpia\n",
    "print(\"\\n--- ¬°LIMPIEZA DE TEXTO EXITOSA! Comparaci√≥n (Primera Fila) ---\")\n",
    "print(\"Original:\", df_text['review'].iloc[0])\n",
    "print(\"Limpia:\", df_text['review_clean'].iloc[0])\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Definir X (features) y Y (target)\n",
    "X = df_text['review_clean']\n",
    "Y = df_text['sentiment']\n",
    "\n",
    "# 2. Dividir los datos antes de vectorizar para evitar 'data leakage'\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Inicializar y Entrenar el Vectorizador TF-IDF\n",
    "# max_features limita el n√∫mero de palabras √∫nicas (columnas) para evitar un exceso de memoria.\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Entrenar (fit) el vectorizador solo con los datos de ENTRENAMIENTO\n",
    "X_train_vectorized = tfidf.fit_transform(X_train)\n",
    "\n",
    "# Aplicar la transformaci√≥n (transform) al conjunto de PRUEBA\n",
    "X_test_vectorized = tfidf.transform(X_test)\n",
    "\n",
    "# 4. Verificaci√≥n de la Matriz Final\n",
    "print(\"\\n--- Verificaci√≥n de la Vectorizaci√≥n ---\")\n",
    "print(f\"Dimensiones de la matriz de entrenamiento (Filas: Rese√±as, Columnas: Palabras): {X_train_vectorized.shape}\")\n",
    "print(f\"N√∫mero de caracter√≠sticas (palabras) usadas: {len(tfidf.get_feature_names_out())}\")\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1. Entrenar el Modelo Naive Bayes\n",
    "print(\"\\nEntrenando Modelo Naive Bayes...\")\n",
    "modelo_nb = MultinomialNB()\n",
    "modelo_nb.fit(X_train_vectorized, Y_train)\n",
    "\n",
    "# 2. Realizar Predicciones\n",
    "Y_pred = modelo_nb.predict(X_test_vectorized)\n",
    "\n",
    "# 3. Evaluaci√≥n del Modelo\n",
    "precision = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"\\n--- Resultados de la Clasificaci√≥n ---\")\n",
    "print(f\"‚úÖ Precisi√≥n (Accuracy) del Modelo: {precision:.4f}\")\n",
    "print(\"\\n--- Informe Detallado de Clasificaci√≥n (Precisi√≥n, Recall, F1-Score) ---\")\n",
    "# El informe detallado es crucial para ver el rendimiento en cada clase (0=Negativo, 1=Positivo)\n",
    "print(classification_report(Y_test, Y_pred, target_names=['Negativo (0)', 'Positivo (1)']))\n",
    "\n",
    "# 1. Obtener los nombres de las 5000 palabras (features)\n",
    "feature_names = np.array(tfidf.get_feature_names_out())\n",
    "\n",
    "# 2. Obtener los logaritmos de las probabilidades para cada clase (0 y 1)\n",
    "# np.exp() se usa para obtener el valor real de probabilidad, aunque el ranking se mantiene con el log.\n",
    "probabilidades_clase_0 = modelo_nb.feature_log_prob_[0]\n",
    "probabilidades_clase_1 = modelo_nb.feature_log_prob_[1]\n",
    "\n",
    "# 3. Calcular el ratio de importancia: P(Palabra|Positivo) / P(Palabra|Negativo)\n",
    "# Restar logaritmos equivale a dividir las probabilidades: log(P1/P0) = log(P1) - log(P0)\n",
    "# Las palabras con mayor diferencia logar√≠tmica (m√°s positivas) son las m√°s discriminantes.\n",
    "ratio_log = probabilidades_clase_1 - probabilidades_clase_0\n",
    "\n",
    "# 4. Crear un DataFrame para ordenar y analizar\n",
    "df_impacto_palabras = pd.DataFrame({\n",
    "    'Palabra': feature_names,\n",
    "    'Ratio_Log': ratio_log\n",
    "})\n",
    "\n",
    "# 5. Obtener las 10 palabras m√°s POSITIVAS (Ratio_Log m√°s alto)\n",
    "top_positivas = df_impacto_palabras.sort_values(by='Ratio_Log', ascending=False).head(10)\n",
    "\n",
    "# 6. Obtener las 10 palabras m√°s NEGATIVAS (Ratio_Log m√°s bajo)\n",
    "top_negativas = df_impacto_palabras.sort_values(by='Ratio_Log', ascending=True).head(10)\n",
    "\n",
    "\n",
    "print(\"\\n--- üåü Top 10 Palabras que Predicen Sentimiento POSITIVO ---\")\n",
    "print(top_positivas.round(4))\n",
    "print(\"\\n--- üíÄ Top 10 Palabras que Predicen Sentimiento NEGATIVO ---\")\n",
    "print(top_negativas.round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3] *",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
